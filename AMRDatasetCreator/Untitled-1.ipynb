{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/david/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1944.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import amrlib\n",
    "from amrlib.alignments.rbw_aligner import RBWAligner\n",
    "from amrlib.graph_processing.annotator import add_lemmas\n",
    "import spacy\n",
    "import penman\n",
    "\n",
    "class SemanticEntailmentAMRDataset:\n",
    "    def __init__(self, dataset_name, amr_parser_path='/home/david/tmp/model_parse_xfm_bart_base-v0_1_0'):\n",
    "\n",
    "        self.amr_parser = amrlib.load_stog_model(amr_parser_path)\n",
    "        self.dataset_name = dataset_name\n",
    "        self.nlp_tokenizer = spacy.load('en_core_web_sm')\n",
    "\n",
    "        if dataset_name == 'hans':\n",
    "            self.dataset = load_dataset('hans')\n",
    "        elif dataset_name in ['mnli', 'wnli', 'qnli', 'mnli_mismatched', 'mnli_matched','cola']:\n",
    "            self.dataset = load_dataset('glue', dataset_name)\n",
    "        else:\n",
    "            raise Exception(f'Dataset {dataset_name} does not exist.')\n",
    "\n",
    "    def splits(self):\n",
    "        return self.dataset.keys()\n",
    "\n",
    "    def to_amr(self, split):\n",
    "        if self.dataset_name != 'cola':\n",
    "            raise Exception(f'Dataset {self.dataset_name} not supported.')\n",
    "        sent_idx_list = [(entry['sentence'], entry['idx']) for entry in  self.dataset[split]]\n",
    "        sent_list, idx_list = list(zip(*sent_idx_list))\n",
    "        sent_list, idx_list = list(sent_list), list(idx_list)\n",
    "        # print(sent_list, idx_list)\n",
    "        parsed_sents = self.amr_parser.parse_sents(sent_list, add_metadata=True)\n",
    "        print('All parsed to AMR')\n",
    "\n",
    "        aligned_amr_sentences =  []\n",
    "        for amr_sentence in parsed_sents:\n",
    "            aligned_amr_sentences.append(self.__aligned_AMR(amr_sentence))\n",
    "\n",
    "        print('All AMR aligned')\n",
    "\n",
    "        processed_amr_sentence_alignment_pairs =  []\n",
    "        for aligned_amr_sentence in aligned_amr_sentences:\n",
    "            processed_amr_sentence_alignment_pairs.append((penman.encode(aligned_amr_sentence),self.__get_alignments(aligned_amr_sentence)))\n",
    "\n",
    "        print('All Tokens aligned')\n",
    "\n",
    "        return processed_amr_sentence_alignment_pairs\n",
    "\n",
    "    def __aligned_AMR(self, arm_graph_string):\n",
    "        pg = add_lemmas(arm_graph_string, snt_key='snt')\n",
    "        aligner = RBWAligner.from_penman_w_json(pg)\n",
    "        penman_graph = aligner.get_penman_graph()\n",
    "        return penman_graph\n",
    "\n",
    "\n",
    "    def __get_alignments(self, penman_graph):\n",
    "        # returns an array where the i-th entry is a 2-tuple of the start and end characters index of the word (the last exclusive!)\n",
    "        # TODO inclusive or exclusive?\n",
    "        alignments = []\n",
    "        ref_token = self.nlp_tokenizer(penman_graph.metadata['snt'])\n",
    "        for i, token in enumerate(json.loads(penman_graph.metadata['tokens'])):\n",
    "            assert token == ref_token[i].text, f'token are unexpectedly different {token} - {ref_token[i].text}'\n",
    "            alignments.append((ref_token[i].idx, ref_token[i].idx + len(ref_token[i])))\n",
    "        return alignments\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = SemanticEntailmentAMRDataset('cola')\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gid=x Start paren present but and is not a new concept\n",
      "gid=x Start paren present but amr-unknown is not a new concept\n",
      "gid=x Start paren present but old is not a new concept\n",
      "gid=x Start paren present but likely-01 is not a new concept\n",
      "gid=x Missing starting paren for node a3/any\n",
      "gid=x Start paren present but name is not a new concept\n",
      "gid=x Initial node constructed when triples not empty, ignoring token.\n",
      "gid=x Missing starting paren for node g2/garden\n",
      "gid=x Start paren present but person is not a new concept\n",
      "gid=x Start paren present but asparagus is not a new concept\n",
      "gid=x Start paren present but eat-01 is not a new concept\n",
      "gid=x Start paren present but name is not a new concept\n",
      "gid=x Start paren present but right-06 is not a new concept\n",
      "gid=x Start paren present but believe-01 is not a new concept\n",
      "gid=x Start paren present but play-11 is not a new concept\n",
      "gid=x Start paren present but drop-01 is not a new concept\n",
      "gid=x Start paren present but drop-01 is not a new concept\n",
      "gid=x Start paren present but have-rel-role-91 is not a new concept\n",
      "gid=x Start paren present but beg-01 is not a new concept\n",
      "gid=x Start paren present but organization is not a new concept\n",
      "gid=x Start paren present but read-01 is not a new concept\n",
      "gid=x Missing starting paren for node n/noon\n",
      "gid=x Start paren present but name is not a new concept\n",
      "gid=x Start paren present but person is not a new concept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parsed to AMR\n",
      "All AMR aligned\n",
      "All Tokens aligned\n"
     ]
    }
   ],
   "source": [
    "l = a.to_amr('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# ::snt Bill whistled past the house.\\n# ::tokens [\"Bill\", \"whistled\", \"past\", \"the\", \"house\", \".\"]\\n# ::lemmas [\"Bill\", \"whistle\", \"past\", \"the\", \"house\", \".\"]\\n# ::alignments 0-1.1.1.1 1-1 2-1.2 4-1.2.1\\n(w / whistle-01~e.1\\n   :ARG0 (p / person\\n            :name (n / name\\n                     :op1 \"Bill\"~e.0))\\n   :path (p2 / past~e.2\\n             :op1 (h / house~e.4)))',\n",
       " [(0, 4), (5, 13), (14, 18), (19, 22), (23, 28), (28, 29)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt Bill whistled past the house.\n",
      "(w / whistle-01\n",
      "      :ARG0 (p / person\n",
      "            :name (n / name\n",
      "                  :op1 \"Bill\"))\n",
      "      :path (p2 / past\n",
      "            :op1 (h / house)))\n",
      "[\"Bill\", \"whistled\", \"past\", \"the\", \"house\", \".\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# ::snt Bill whistled past the house.\\n# ::tokens [\"Bill\", \"whistled\", \"past\", \"the\", \"house\", \".\"]\\n# ::lemmas [\"Bill\", \"whistle\", \"past\", \"the\", \"house\", \".\"]\\n# ::alignments 0-1.1.1.1 1-1 2-1.2 4-1.2.1\\n(w / whistle-01~e.1\\n   :ARG0 (p / person\\n            :name (n / name\\n                     :op1 \"Bill\"~e.0))\\n   :path (p2 / past~e.2\\n             :op1 (h / house~e.4)))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ps[0])\n",
    "import penman\n",
    "b = a.aligned_AMR(ps[0])\n",
    "print(b.metadata['tokens'])\n",
    "penman.encode(a.aligned_AMR(ps[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = {\n",
    "    'cola': ['train','validation','test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/david/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1405.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "www = load_dataset('glue','cola')\n",
    "print(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = {\n",
    "    'cola': ['train','validation','test']\n",
    "}\n",
    "\n",
    "def preprocess_all_data(tasks):\n",
    "    for dataset in tasks.keys():\n",
    "        ds = SemanticEntailmentAMRDataset(dataset)\n",
    "        for task in tasks[dataset]:\n",
    "            res = ds.to_amr('task')\n",
    "            f_name = f'amr_data_{dataset}_{task}.json'\n",
    "            with open(f_name, 'w') as f:\n",
    "                json.dump(res,f)\n",
    "            print(f'Just finished {f_name}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    preprocess_all_data(combos)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ac709cedd62974675cfce288e81988ef41c7c0605da83201e5f3d701a79c198"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AMRDatasetCreator-vNNjLCpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
